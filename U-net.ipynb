{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io import read_image, write_png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--sigma\", type=float, dest=\"sigma\",\n",
    "                    help=\"Standard deviation of the noise (noise level). Should be between 0 and 50.\", default=30)\n",
    "parser.add_argument(\"--in\", type=str, dest=\"path_in\",\n",
    "                    help=\"Path to the image to denoise (PNG or JPEG).\", default=\"./test_images/cameraman.png\")\n",
    "parser.add_argument(\"--out\", type=str, dest=\"path_out\",\n",
    "                    help=\"Path to save the denoised image.\", default=\"./img_lichi.png\")\n",
    "parser.add_argument(\"--add_noise\", action='store_true',\n",
    "                    help=\"Add artificial Gaussian noise to the image.\", default=True)\n",
    "\n",
    "# To avoid conflicts with Jupyter's arguments, pass an empty list to parse_args()\n",
    "args = parser.parse_args(args=[])\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Read image and Add noise\n",
    "img = read_image(args.path_in)[None, :, :, :].float().to(device)\n",
    "img_noisy = img + args.sigma * torch.randn_like(img) if args.add_noise else img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super(conv_block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class up_conv(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super(up_conv, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class U_Net(nn.Module):\n",
    "    def __init__(self, img_ch=1, output_ch=1):\n",
    "        super(U_Net, self).__init__()\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv1 = conv_block(ch_in=img_ch, ch_out=64)\n",
    "        self.conv2 = conv_block(ch_in=64, ch_out=128)\n",
    "        self.conv3 = conv_block(ch_in=128, ch_out=256)\n",
    "        self.conv4 = conv_block(ch_in=256, ch_out=512)\n",
    "        self.conv5 = conv_block(ch_in=512, ch_out=1024)\n",
    "\n",
    "        self.up5 = up_conv(ch_in=1024, ch_out=512)\n",
    "        self.up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
    "        self.up4 = up_conv(ch_in=512, ch_out=256)\n",
    "        self.up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
    "        self.up3 = up_conv(ch_in=256, ch_out=128)\n",
    "        self.up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
    "        self.up2 = up_conv(ch_in=128, ch_out=64)\n",
    "        self.up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
    "\n",
    "        self.up_conv1 = nn.Conv2d(64, output_ch, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.maxpool(x1)\n",
    "        x2 = self.conv2(x2)\n",
    "        x3 = self.maxpool(x2)\n",
    "        x3 = self.conv3(x3)\n",
    "        x4 = self.maxpool(x3)\n",
    "        x4 = self.conv4(x4)\n",
    "        x5 = self.maxpool(x4)\n",
    "        x5 = self.conv5(x5)\n",
    "\n",
    "        d5 = self.up5(x5)\n",
    "        d5 = torch.cat((x4, d5), dim=1)\n",
    "        d5 = self.up_conv5(d5)\n",
    "\n",
    "        d4 = self.up4(d5)\n",
    "        d4 = torch.cat((x3, d4), dim=1)\n",
    "        d4 = self.up_conv4(d4)\n",
    "\n",
    "        d3 = self.up3(d4)\n",
    "        d3 = torch.cat((x2, d3), dim=1)\n",
    "        d3 = self.up_conv3(d3)\n",
    "\n",
    "        d2 = self.up2(d3)\n",
    "        d2 = torch.cat((x1, d2), dim=1)\n",
    "        d2 = self.up_conv2(d2)\n",
    "\n",
    "        d1 = self.up_conv1(d2)\n",
    "        return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = U_Net(img_ch=1, output_ch=1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 234.239731\n",
      "Epoch 2/100, Loss: 232.548737\n",
      "Epoch 3/100, Loss: 228.991150\n",
      "Epoch 4/100, Loss: 219.061920\n",
      "Epoch 5/100, Loss: 217.956680\n",
      "Epoch 6/100, Loss: 213.243607\n",
      "Epoch 7/100, Loss: 206.292557\n",
      "Epoch 8/100, Loss: 203.736053\n",
      "Epoch 9/100, Loss: 204.720245\n",
      "Epoch 10/100, Loss: 201.171692\n",
      "Epoch 11/100, Loss: 198.926086\n",
      "Epoch 12/100, Loss: 192.928177\n",
      "Epoch 13/100, Loss: 186.848633\n",
      "Epoch 14/100, Loss: 187.060272\n",
      "Epoch 15/100, Loss: 182.014069\n",
      "Epoch 16/100, Loss: 178.458984\n",
      "Epoch 17/100, Loss: 173.670807\n",
      "Epoch 18/100, Loss: 174.541367\n",
      "Epoch 19/100, Loss: 175.195038\n",
      "Epoch 20/100, Loss: 173.221436\n",
      "Epoch 21/100, Loss: 169.434143\n",
      "Epoch 22/100, Loss: 166.464371\n",
      "Epoch 23/100, Loss: 169.682938\n",
      "Epoch 24/100, Loss: 179.470367\n",
      "Epoch 25/100, Loss: 166.946503\n",
      "Epoch 26/100, Loss: 157.082611\n",
      "Epoch 27/100, Loss: 161.061310\n",
      "Epoch 28/100, Loss: 155.353546\n",
      "Epoch 29/100, Loss: 150.937485\n",
      "Epoch 30/100, Loss: 151.647095\n",
      "Epoch 31/100, Loss: 152.720413\n",
      "Epoch 32/100, Loss: 146.687195\n",
      "Epoch 33/100, Loss: 143.344025\n",
      "Epoch 34/100, Loss: 141.802658\n",
      "Epoch 35/100, Loss: 140.544296\n",
      "Epoch 36/100, Loss: 138.245193\n",
      "Epoch 37/100, Loss: 136.630890\n",
      "Epoch 38/100, Loss: 134.947205\n",
      "Epoch 39/100, Loss: 134.020386\n",
      "Epoch 40/100, Loss: 132.965897\n",
      "Epoch 41/100, Loss: 130.167068\n",
      "Epoch 42/100, Loss: 128.487305\n",
      "Epoch 43/100, Loss: 128.837250\n",
      "Epoch 44/100, Loss: 130.041931\n",
      "Epoch 45/100, Loss: 130.273849\n",
      "Epoch 46/100, Loss: 131.570831\n",
      "Epoch 47/100, Loss: 133.712524\n",
      "Epoch 48/100, Loss: 135.290161\n",
      "Epoch 49/100, Loss: 125.420578\n",
      "Epoch 50/100, Loss: 118.559669\n",
      "Epoch 51/100, Loss: 117.782135\n",
      "Epoch 52/100, Loss: 120.416771\n",
      "Epoch 53/100, Loss: 118.508659\n",
      "Epoch 54/100, Loss: 114.845947\n",
      "Epoch 55/100, Loss: 114.315445\n",
      "Epoch 56/100, Loss: 115.156212\n",
      "Epoch 57/100, Loss: 109.596733\n",
      "Epoch 58/100, Loss: 106.753677\n",
      "Epoch 59/100, Loss: 108.472542\n",
      "Epoch 60/100, Loss: 107.426834\n",
      "Epoch 61/100, Loss: 104.909119\n",
      "Epoch 62/100, Loss: 104.243828\n",
      "Epoch 63/100, Loss: 103.451698\n",
      "Epoch 64/100, Loss: 103.514511\n",
      "Epoch 65/100, Loss: 101.674637\n",
      "Epoch 66/100, Loss: 104.572113\n",
      "Epoch 67/100, Loss: 111.182571\n",
      "Epoch 68/100, Loss: 123.679214\n",
      "Epoch 69/100, Loss: 106.573685\n",
      "Epoch 70/100, Loss: 96.548904\n",
      "Epoch 71/100, Loss: 105.443550\n",
      "Epoch 72/100, Loss: 101.006706\n",
      "Epoch 73/100, Loss: 95.338264\n",
      "Epoch 74/100, Loss: 99.109772\n",
      "Epoch 75/100, Loss: 94.075333\n",
      "Epoch 76/100, Loss: 93.054253\n",
      "Epoch 77/100, Loss: 93.268456\n",
      "Epoch 78/100, Loss: 90.212990\n",
      "Epoch 79/100, Loss: 89.224731\n",
      "Epoch 80/100, Loss: 91.678833\n",
      "Epoch 81/100, Loss: 90.404129\n",
      "Epoch 82/100, Loss: 100.050453\n",
      "Epoch 83/100, Loss: 113.732407\n",
      "Epoch 84/100, Loss: 106.844727\n",
      "Epoch 85/100, Loss: 93.227058\n",
      "Epoch 86/100, Loss: 97.483727\n",
      "Epoch 87/100, Loss: 93.430473\n",
      "Epoch 88/100, Loss: 90.600052\n",
      "Epoch 89/100, Loss: 91.449982\n",
      "Epoch 90/100, Loss: 86.095299\n",
      "Epoch 91/100, Loss: 84.376953\n",
      "Epoch 92/100, Loss: 84.700897\n",
      "Epoch 93/100, Loss: 81.686188\n",
      "Epoch 94/100, Loss: 78.949875\n",
      "Epoch 95/100, Loss: 80.144653\n",
      "Epoch 96/100, Loss: 76.066826\n",
      "Epoch 97/100, Loss: 77.055794\n",
      "Epoch 98/100, Loss: 73.238083\n",
      "Epoch 99/100, Loss: 74.895058\n",
      "Epoch 100/100, Loss: 71.868622\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    output = model(x)\n",
    "    loss = criterion(output, img)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR LLR: 29.58 dB\n"
     ]
    }
   ],
   "source": [
    "output = model(x)\n",
    "\n",
    "psnr = 10*torch.log10(255**2 / torch.mean((output - img)**2))\n",
    "print(\"PSNR LLR:\", round(float(psnr), 2), \"dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1eae3fb3d22bfe9d65f381451681dc210dcc0b10938e5e2e079c6bf80fa6ee79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
